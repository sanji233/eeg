{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e43e4382",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm \n",
    "import mne\n",
    "import pandas as pd\n",
    "import os, glob, random, warnings, numpy as np, matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import (EarlyStopping, ModelCheckpoint,\n",
    "                                         LearningRateMonitor)\n",
    "from torchmetrics.classification import Accuracy, ConfusionMatrix, MulticlassF1Score\n",
    "from torch.utils import data as torch_data\n",
    "from sklearn.metrics import classification_report\n",
    "from pytorch_lightning.utilities import rank_zero_only \n",
    "\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as torch_data\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from pytorch_lightning.utilities import rank_zero_only\n",
    "\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from torchmetrics.classification import Accuracy\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['axes.facecolor'] = 'lightgray'\n",
    "\n",
    "# 定义常量\n",
    "EPOCH_DURATION = 6.0  # 每个epoch的秒数\n",
    "SEGMENT_DURATION = 1.0  # 每个切片的秒数\n",
    "N_SEGMENTS = int(EPOCH_DURATION / SEGMENT_DURATION)  # 每个epoch切成6片\n",
    "\n",
    "# 标签映射\n",
    "label_map = {\n",
    "    769: \"OVTK_GDF_Left\", \n",
    "    770: \"OVTK_GDF_Right\",\n",
    "    780: \"OVTK_GDF_Up\",\n",
    "    774: \"OVTK_GDF_Down\",\n",
    "    32769: \"OVTK_StimulationId_ExperimentStart\",\n",
    "    32775: \"OVTK_StimulationId_BaselineStart\",\n",
    "    33026: \"OVTK_GDF_Feedback_Continuous\"\n",
    "}\n",
    "\n",
    "# 数值标签映射（用于分类）\n",
    "numeric_label_map = {\n",
    "    769: 0,  # 左\n",
    "    770: 1,  # 右\n",
    "    780: 2,  # 上\n",
    "    774: 3,  # 下\n",
    "    999: 4   # 静息\n",
    "}\n",
    "\n",
    "# EEG通道列\n",
    "channel_cols = [\n",
    "    'Channel 1', 'Channel 2', 'Channel 3', 'Channel 4',\n",
    "    'Channel 5', 'Channel 6', 'Channel 7', 'Channel 8'\n",
    "]   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61201cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找到 3 个CSV文件\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理文件:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理文件: motor-imagery-1-[2025.04.20-12.14.27].csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiong\\AppData\\Local\\Temp\\ipykernel_19748\\2200368940.py:38: DtypeWarning: Columns (13,14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=8, n_times=101728\n",
      "    Range : 0 ... 101727 =      0.000 ...   406.908 secs\n",
      "Ready.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n",
      "Not setting metadata\n",
      "25 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 25 events and 1501 original time points ...\n",
      "0 bad epochs dropped\n",
      "任务相关epochs数量: 25\n",
      "Not setting metadata\n",
      "66 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 66 events and 1501 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s finished\n",
      "C:\\Users\\xiong\\AppData\\Local\\Temp\\ipykernel_19748\\2200368940.py:133: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  X_task = (task_epochs.get_data() * 1e-6).astype(np.float32)\n",
      "C:\\Users\\xiong\\AppData\\Local\\Temp\\ipykernel_19748\\2200368940.py:183: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  X_rest = (rest_epochs.get_data() * 1e-6).astype(np.float32)\n",
      "处理文件:  33%|███▎      | 1/3 [00:00<00:01,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "静息epochs数量: 66\n",
      "原始epochs总数: 91\n",
      "切片后segments总数: 546\n",
      "切片后数据形状: (546, 8, 250)\n",
      "正在处理文件: motor-imagery-1-[2025.04.20-12.22.41].csv\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=103744\n",
      "    Range : 0 ... 103743 =      0.000 ...   414.972 secs\n",
      "Ready.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n",
      "Not setting metadata\n",
      "25 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 25 events and 1501 original time points ...\n",
      "0 bad epochs dropped\n",
      "任务相关epochs数量: 25\n",
      "Not setting metadata\n",
      "67 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 67 events and 1501 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s finished\n",
      "C:\\Users\\xiong\\AppData\\Local\\Temp\\ipykernel_19748\\2200368940.py:133: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  X_task = (task_epochs.get_data() * 1e-6).astype(np.float32)\n",
      "C:\\Users\\xiong\\AppData\\Local\\Temp\\ipykernel_19748\\2200368940.py:183: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  X_rest = (rest_epochs.get_data() * 1e-6).astype(np.float32)\n",
      "处理文件:  67%|██████▋   | 2/3 [00:00<00:00,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "静息epochs数量: 67\n",
      "原始epochs总数: 92\n",
      "切片后segments总数: 552\n",
      "切片后数据形状: (552, 8, 250)\n",
      "正在处理文件: motor-imagery-1-[2025.04.20-12.31.29].csv\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=101248\n",
      "    Range : 0 ... 101247 =      0.000 ...   404.988 secs\n",
      "Ready.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n",
      "Not setting metadata\n",
      "25 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 25 events and 1501 original time points ...\n",
      "0 bad epochs dropped\n",
      "任务相关epochs数量: 25\n",
      "Not setting metadata\n",
      "66 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 66 events and 1501 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiong\\AppData\\Local\\Temp\\ipykernel_19748\\2200368940.py:38: DtypeWarning: Columns (13,14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s finished\n",
      "C:\\Users\\xiong\\AppData\\Local\\Temp\\ipykernel_19748\\2200368940.py:133: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  X_task = (task_epochs.get_data() * 1e-6).astype(np.float32)\n",
      "C:\\Users\\xiong\\AppData\\Local\\Temp\\ipykernel_19748\\2200368940.py:183: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  X_rest = (rest_epochs.get_data() * 1e-6).astype(np.float32)\n",
      "处理文件: 100%|██████████| 3/3 [00:01<00:00,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "静息epochs数量: 66\n",
      "原始epochs总数: 91\n",
      "切片后segments总数: 546\n",
      "切片后数据形状: (546, 8, 250)\n",
      "所有文件处理完成!\n",
      "总数据形状: (1644, 8, 250)\n",
      "总标签形状: (1644,)\n",
      "类别 0 (OVTK_GDF_Left): 108 样本 (6.57%)\n",
      "类别 1 (OVTK_GDF_Right): 114 样本 (6.93%)\n",
      "类别 2 (OVTK_GDF_Up): 120 样本 (7.30%)\n",
      "类别 3 (OVTK_GDF_Down): 108 样本 (6.57%)\n",
      "类别 4 (静息): 1194 样本 (72.63%)\n",
      "训练集大小: 1314 样本\n",
      "验证集大小: 165 样本\n",
      "测试集大小: 165 样本\n",
      "类别 0 分布: 训练集 86, 验证集 11, 测试集 11\n",
      "类别 1 分布: 训练集 92, 验证集 11, 测试集 11\n",
      "类别 2 分布: 训练集 96, 验证集 12, 测试集 12\n",
      "类别 3 分布: 训练集 86, 验证集 11, 测试集 11\n",
      "类别 4 分布: 训练集 954, 验证集 120, 测试集 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 设置常量\n",
    "EPOCH_DURATION = 6.0  # 每个epoch的秒数\n",
    "SEGMENT_DURATION = 1.0  # 每个切片的秒数\n",
    "N_SEGMENTS = int(EPOCH_DURATION / SEGMENT_DURATION)  # 每个epoch切成6片\n",
    "SAMPLING_FREQ = 250.0  # 采样频率\n",
    "\n",
    "# 标签映射\n",
    "label_map = {\n",
    "    769: \"OVTK_GDF_Left\", \n",
    "    770: \"OVTK_GDF_Right\",\n",
    "    780: \"OVTK_GDF_Up\",\n",
    "    774: \"OVTK_GDF_Down\",\n",
    "    32769: \"OVTK_StimulationId_ExperimentStart\",\n",
    "    32775: \"OVTK_StimulationId_BaselineStart\",\n",
    "    33026: \"OVTK_GDF_Feedback_Continuous\"\n",
    "}\n",
    "\n",
    "# 数值标签映射（用于分类）\n",
    "numeric_label_map = {\n",
    "    769: 0,  # 左\n",
    "    770: 1,  # 右\n",
    "    780: 2,  # 上\n",
    "    774: 3,  # 下\n",
    "    999: 4   # 静息\n",
    "}\n",
    "\n",
    "# EEG通道列\n",
    "channel_cols = [\n",
    "    'Channel 1', 'Channel 2', 'Channel 3', 'Channel 4',\n",
    "    'Channel 5', 'Channel 6', 'Channel 7', 'Channel 8'\n",
    "]\n",
    "\n",
    "def preprocess_csv(file_path):\n",
    "    \"\"\"预处理单个CSV文件\"\"\"\n",
    "    print(f\"正在处理文件: {os.path.basename(file_path)}\")\n",
    "    \n",
    "    # 读取CSV文件\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # 删除不需要的通道（如果存在）\n",
    "    columns_to_drop = [col for col in [\"Channel 9\", \"Channel 10\", \"Channel 11\"] if col in df.columns]\n",
    "    if columns_to_drop:\n",
    "        df.drop(columns=columns_to_drop, inplace=True)\n",
    "    \n",
    "    # 处理事件ID、日期和持续时间列，保留冒号前的部分\n",
    "    def keep_first_part(x):\n",
    "        if not isinstance(x, str):\n",
    "            x = \"\" if pd.isna(x) else str(x)\n",
    "        return x.split(\":\")[0] if x else \"\"\n",
    "    \n",
    "    for col in [\"Event Id\", \"Event Date\", \"Event Duration\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna(\"\").apply(keep_first_part)\n",
    "    \n",
    "    # 清空重复事件行\n",
    "    if \"Event Id\" in df.columns and \"Event Date\" in df.columns and \"Event Duration\" in df.columns:\n",
    "        same_mask = df[\"Event Id\"] == df[\"Event Id\"].shift(-1)\n",
    "        rows_to_blank = same_mask.index[same_mask]\n",
    "        rows_to_blank = rows_to_blank + 1\n",
    "        rows_to_blank = rows_to_blank[rows_to_blank < len(df)]\n",
    "        df.loc[rows_to_blank, [\"Event Id\", \"Event Date\", \"Event Duration\"]] = \"\"\n",
    "        \n",
    "        # 转换为数值类型\n",
    "        df[\"Event Id\"] = pd.to_numeric(df[\"Event Id\"], errors=\"coerce\")\n",
    "        df[\"Event Date\"] = pd.to_numeric(df[\"Event Date\"], errors=\"coerce\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_raw_from_dataframe(df):\n",
    "    \"\"\"从DataFrame创建MNE Raw对象\"\"\"\n",
    "    # 提取EEG数据\n",
    "    data = df[channel_cols].to_numpy().T\n",
    "    \n",
    "    # 创建MNE信息对象\n",
    "    ch_names = ['ch1', 'ch2', 'ch3', 'ch4', 'ch5', 'ch6', 'ch7', 'ch8']\n",
    "    ch_types = ['eeg'] * 8\n",
    "    info = mne.create_info(ch_names=ch_names, sfreq=SAMPLING_FREQ, ch_types=ch_types)\n",
    "    \n",
    "    # 创建Raw对象\n",
    "    raw = mne.io.RawArray(data, info)\n",
    "    \n",
    "    # 应用50Hz陷波滤波器（去除电源线噪声）\n",
    "    raw.notch_filter(freqs=[50], picks='eeg')\n",
    "    \n",
    "    return raw\n",
    "\n",
    "def extract_events_from_dataframe(df, raw):\n",
    "    \"\"\"从DataFrame提取事件数据\"\"\"\n",
    "    events = []\n",
    "    \n",
    "    if \"Event Id\" in df.columns and \"Event Date\" in df.columns:\n",
    "        event_indices = df.index[~pd.isna(df[\"Event Id\"]) & (df[\"Event Id\"] != \"\")]\n",
    "        \n",
    "        for idx in event_indices:\n",
    "            event_id = df.loc[idx, \"Event Id\"]\n",
    "            event_date = df.loc[idx, \"Event Date\"]\n",
    "            \n",
    "            # 只保留任务相关事件\n",
    "            if event_id in [769, 770, 780, 774]:\n",
    "                # 事件样本点位置\n",
    "                sample = int(event_date)\n",
    "                \n",
    "                # 创建事件元组 [sample, 0, event_id]\n",
    "                events.append([sample, 0, int(event_id)])\n",
    "    \n",
    "    return np.array(events, dtype=int) if events else np.empty((0, 3), dtype=int)\n",
    "\n",
    "def process_eeg_data(raw, events):\n",
    "    \"\"\"\n",
    "    处理EEG数据\n",
    "    提取所有类别的epochs并进行一致的切片\n",
    "    \"\"\"\n",
    "    \n",
    "    # 提取任务相关epochs（左、右、上、下）\n",
    "    task_event_id = {\n",
    "        'left': 769,\n",
    "        'right': 770,\n",
    "        'up': 780,\n",
    "        'down': 774\n",
    "    }\n",
    "    \n",
    "    task_epochs = mne.Epochs(\n",
    "        raw,\n",
    "        events=events,\n",
    "        event_id=task_event_id,\n",
    "        tmin=0.0,\n",
    "        tmax=EPOCH_DURATION,\n",
    "        baseline=None,\n",
    "        picks='eeg',\n",
    "        preload=True\n",
    "    )\n",
    "    \n",
    "    X_task = (task_epochs.get_data() * 1e-6).astype(np.float32)\n",
    "    y_task = np.array([numeric_label_map[val] for val in task_epochs.events[:, 2]], dtype=np.int64)\n",
    "    \n",
    "    print(f\"任务相关epochs数量: {len(task_epochs)}\")\n",
    "    \n",
    "    # 标记已被任务epochs占用的样本点\n",
    "    used_samples = np.zeros(len(raw.times), dtype=bool)\n",
    "    \n",
    "    for idx in range(len(task_epochs)):\n",
    "        event_sample = task_epochs.events[idx, 0]\n",
    "        start_sample = event_sample\n",
    "        end_sample = start_sample + int(EPOCH_DURATION * raw.info['sfreq'])\n",
    "        if end_sample <= len(used_samples):\n",
    "            used_samples[start_sample:end_sample] = True\n",
    "    \n",
    "    # 寻找未被占用的样本点作为静息epochs\n",
    "    rest_events = []\n",
    "    rest_length = int(EPOCH_DURATION * raw.info['sfreq'])\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(used_samples):\n",
    "        if not used_samples[i]:\n",
    "            start_sample = i\n",
    "            end_sample = min(start_sample + rest_length, len(used_samples))\n",
    "            \n",
    "            # 确保整个区间没有被占用\n",
    "            if end_sample - start_sample >= rest_length and not any(used_samples[start_sample:end_sample]):\n",
    "                rest_events.append([start_sample, 0, 999])  # 999为静息状态代码\n",
    "                i = end_sample\n",
    "            else:\n",
    "                i += 1\n",
    "        else:\n",
    "            i += 1\n",
    "    \n",
    "    rest_events = np.array(rest_events, dtype=int) if rest_events else np.empty((0, 3), dtype=int)\n",
    "    \n",
    "    # 创建静息epochs\n",
    "    if len(rest_events) > 0:\n",
    "        rest_event_id = {'rest': 999}\n",
    "        rest_epochs = mne.Epochs(\n",
    "            raw,\n",
    "            events=rest_events,\n",
    "            event_id=rest_event_id,\n",
    "            tmin=0.0,\n",
    "            tmax=EPOCH_DURATION,\n",
    "            baseline=None,\n",
    "            picks='eeg',\n",
    "            preload=True\n",
    "        )\n",
    "        \n",
    "        X_rest = (rest_epochs.get_data() * 1e-6).astype(np.float32)\n",
    "        y_rest = np.ones(len(rest_epochs), dtype=np.int64) * numeric_label_map[999]\n",
    "        \n",
    "        print(f\"静息epochs数量: {len(rest_epochs)}\")\n",
    "        \n",
    "        # 合并任务和静息数据\n",
    "        X_combined = np.vstack([X_task, X_rest])\n",
    "        y_combined = np.concatenate([y_task, y_rest])\n",
    "    else:\n",
    "        print(\"未找到静息epochs\")\n",
    "        X_combined = X_task\n",
    "        y_combined = y_task\n",
    "    \n",
    "    # 对所有epochs进行一致的切片处理\n",
    "    all_segments = []\n",
    "    all_segment_labels = []\n",
    "    \n",
    "    samples_per_segment = int(raw.info['sfreq'] * SEGMENT_DURATION)\n",
    "    \n",
    "    for i in range(len(X_combined)):\n",
    "        epoch_data = X_combined[i]\n",
    "        label = y_combined[i]\n",
    "        \n",
    "        for j in range(N_SEGMENTS):\n",
    "            start_idx = j * samples_per_segment\n",
    "            end_idx = (j + 1) * samples_per_segment\n",
    "            \n",
    "            if end_idx <= epoch_data.shape[1]:  # 确保不越界\n",
    "                segment_data = epoch_data[:, start_idx:end_idx]\n",
    "                all_segments.append(segment_data)\n",
    "                all_segment_labels.append(label)\n",
    "    \n",
    "    X_segments = np.array(all_segments)\n",
    "    y_segments = np.array(all_segment_labels)\n",
    "    \n",
    "    print(f\"原始epochs总数: {len(X_combined)}\")\n",
    "    print(f\"切片后segments总数: {len(all_segments)}\")\n",
    "    print(f\"切片后数据形状: {X_segments.shape}\")\n",
    "\n",
    "    return X_segments, y_segments\n",
    "\n",
    "def get_eeg_channels(raw):\n",
    "    \"\"\"获取EEG通道数\"\"\"\n",
    "    eeg_channel_inds = mne.pick_types(\n",
    "        raw.info,\n",
    "        meg=False,\n",
    "        eeg=True,\n",
    "        stim=False,\n",
    "        eog=False,\n",
    "        exclude='bads',\n",
    "    )\n",
    "    return len(eeg_channel_inds)\n",
    "\n",
    "def load_all_csv_files(folder_path, pattern=\"*.csv\"):\n",
    "    \"\"\"加载文件夹中所有符合模式的CSV文件，并处理它们\"\"\"\n",
    "    all_X_segments = []\n",
    "    all_y_segments = []\n",
    "    \n",
    "    # 获取所有匹配的CSV文件\n",
    "    csv_files = glob.glob(os.path.join(folder_path, pattern))\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(f\"在 {folder_path} 中未找到符合 {pattern} 的CSV文件\")\n",
    "        return None, None\n",
    "    \n",
    "    print(f\"找到 {len(csv_files)} 个CSV文件\")\n",
    "    \n",
    "    # 处理每个CSV文件\n",
    "    for file_path in tqdm(csv_files, desc=\"处理文件\"):\n",
    "        try:\n",
    "            # 预处理CSV\n",
    "            df = preprocess_csv(file_path)\n",
    "            \n",
    "            # 创建Raw对象\n",
    "            raw = create_raw_from_dataframe(df)\n",
    "            \n",
    "            # 提取事件\n",
    "            events = extract_events_from_dataframe(df, raw)\n",
    "            \n",
    "            if len(events) > 0:\n",
    "                # 处理EEG数据并获取切片\n",
    "                X_segments, y_segments = process_eeg_data(raw, events)\n",
    "                \n",
    "                # 添加到总集合\n",
    "                all_X_segments.append(X_segments)\n",
    "                all_y_segments.append(y_segments)\n",
    "            else:\n",
    "                print(f\"文件 {os.path.basename(file_path)} 中未找到有效事件\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"处理文件 {os.path.basename(file_path)} 时出错: {str(e)}\")\n",
    "    \n",
    "    # 合并所有数据\n",
    "    if all_X_segments and all_y_segments:\n",
    "        X_all = np.vstack(all_X_segments)\n",
    "        y_all = np.concatenate(all_y_segments)\n",
    "        \n",
    "        print(f\"所有文件处理完成!\")\n",
    "        print(f\"总数据形状: {X_all.shape}\")\n",
    "        print(f\"总标签形状: {y_all.shape}\")\n",
    "        \n",
    "        # 显示每个类别的样本计数\n",
    "        for i in range(5):\n",
    "            count = np.sum(y_all == i)\n",
    "            percent = count / len(y_all) * 100\n",
    "            print(f\"类别 {i} ({list(label_map.values())[i] if i < 4 else '静息'}): {count} 样本 ({percent:.2f}%)\")\n",
    "        \n",
    "        return X_all, y_all\n",
    "    else:\n",
    "        print(\"未能从任何文件中提取到有效数据\")\n",
    "        return None, None\n",
    "\n",
    "class EEGDataset(torch_data.Dataset):\n",
    "    \"\"\"\n",
    "    处理EEG数据的Dataset类，支持五类分类（左、右、上、下、静息）\n",
    "    并提供训练、验证和测试集的拆分功能\n",
    "    \"\"\"\n",
    "    def __init__(self, x, y=None, inference=False, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1, random_state=42):\n",
    "        \"\"\"\n",
    "        初始化EEG数据集\n",
    "        \n",
    "        参数:\n",
    "            x: 形状为(n_samples, n_channels, n_times)的numpy数组\n",
    "            y: 形状为(n_samples,)的numpy数组，类别标签(0-4对应左、右、上、下、静息)\n",
    "            inference: 是否为推理模式（不需要标签）\n",
    "            train_ratio: 训练集比例\n",
    "            val_ratio: 验证集比例\n",
    "            test_ratio: 测试集比例\n",
    "            random_state: 随机种子，用于数据集拆分\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.__split = None\n",
    "        \n",
    "        # 确保比例和为1\n",
    "        assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-10, \"数据集比例必须和为1\"\n",
    "        \n",
    "        if not inference:\n",
    "            # 使用sklearn的train_test_split进行更可靠的拆分\n",
    "            # 首先分离出测试集\n",
    "            X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "                x, y, test_size=test_ratio, random_state=random_state, stratify=y\n",
    "            )\n",
    "            \n",
    "            # 再从剩余数据中分离出验证集\n",
    "            val_ratio_adjusted = val_ratio / (train_ratio + val_ratio)  # 调整验证集比例\n",
    "            X_train, X_val, y_train, y_val = train_test_split(\n",
    "                X_temp, y_temp, test_size=val_ratio_adjusted, \n",
    "                random_state=random_state, stratify=y_temp\n",
    "            )\n",
    "            \n",
    "            self.train_ds = {\n",
    "                'x': X_train,\n",
    "                'y': y_train,\n",
    "            }\n",
    "            self.val_ds = {\n",
    "                'x': X_val,\n",
    "                'y': y_val,\n",
    "            }\n",
    "            self.test_ds = {\n",
    "                'x': X_test,\n",
    "                'y': y_test,\n",
    "            }\n",
    "            \n",
    "            # 打印每个集合的样本数和类别分布\n",
    "            print(f\"训练集大小: {len(X_train)} 样本\")\n",
    "            print(f\"验证集大小: {len(X_val)} 样本\")\n",
    "            print(f\"测试集大小: {len(X_test)} 样本\")\n",
    "            \n",
    "            for i in range(5):  # 五类: 0-左, 1-右, 2-上, 3-下, 4-静息\n",
    "                print(f\"类别 {i} 分布: 训练集 {sum(y_train == i)}, \"\n",
    "                      f\"验证集 {sum(y_val == i)}, 测试集 {sum(y_test == i)}\")\n",
    "        else:\n",
    "            self.inference_ds = {'x': x}\n",
    "            print(f\"推理数据集大小: {len(x)} 样本\")\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"返回当前拆分的数据集长度\"\"\"\n",
    "        return len(self.dataset['x'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"获取指定索引的样本\"\"\"\n",
    "        x_ = torch.tensor(self.dataset['x'][idx], dtype=torch.float32)  # shape=(n_channels, n_times)\n",
    "        \n",
    "        if self.__split != \"inference\":\n",
    "            y_ = torch.tensor(self.dataset['y'][idx], dtype=torch.long)  # 使用long类型用于分类\n",
    "            return x_, y_\n",
    "        else:\n",
    "            return x_\n",
    "\n",
    "    def split(self, __split):\n",
    "        \"\"\"设置当前使用的数据集拆分\"\"\"\n",
    "        self.__split = __split\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def dataset(self):\n",
    "        \"\"\"根据当前拆分返回相应的数据集\"\"\"\n",
    "        assert self.__split is not None, \"必须先指定数据集拆分(train/val/test/inference)!\"\n",
    "        \n",
    "        if self.__split == \"train\":\n",
    "            return self.train_ds\n",
    "        elif self.__split == \"val\":\n",
    "            return self.val_ds\n",
    "        elif self.__split == \"test\":\n",
    "            return self.test_ds\n",
    "        elif self.__split == \"inference\":\n",
    "            return self.inference_ds\n",
    "        else:\n",
    "            raise ValueError(f\"未知的数据集拆分: {self.__split}\")\n",
    "\n",
    "    def get_loaders(self, batch_size=32, num_workers=4):\n",
    "        \"\"\"获取所有数据加载器\"\"\"\n",
    "        train_loader = DataLoader(\n",
    "            self.split(\"train\"), batch_size=batch_size, shuffle=True, \n",
    "            num_workers=num_workers, pin_memory=True\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            self.split(\"val\"), batch_size=batch_size, shuffle=False, \n",
    "            num_workers=num_workers, pin_memory=True\n",
    "        )\n",
    "        \n",
    "        test_loader = DataLoader(\n",
    "            self.split(\"test\"), batch_size=batch_size, shuffle=False, \n",
    "            num_workers=num_workers, pin_memory=True\n",
    "        )\n",
    "        \n",
    "        return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "data_folder = \"D:/data/code/eeg/OpenViBE/data/TEST\"\n",
    "X_all, y_all = load_all_csv_files(data_folder)\n",
    "    \n",
    "if X_all is not None and y_all is not None:\n",
    "    eeg_dataset = EEGDataset(X_all, y_all)\n",
    "    train_loader, val_loader, test_loader = eeg_dataset.get_loaders(batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65f19eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "\n",
    "class AvgMeter:\n",
    "    \"\"\"滑动窗口平均；窗口大小 = num\"\"\"\n",
    "    def __init__(self, num: int = 40):\n",
    "        self.num = num\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.losses: list[torch.Tensor] = []\n",
    "\n",
    "    def update(self, val: torch.Tensor):\n",
    "        self.losses.append(val.detach().clone())\n",
    "\n",
    "    def show(self) -> torch.Tensor:\n",
    "        if len(self.losses) == 0:\n",
    "            return torch.tensor(0.0, device=self.losses[0].device)\n",
    "        recent = self.losses[-self.num :]\n",
    "        return torch.stack(recent).mean()\n",
    "\n",
    "\n",
    "class ModelWrapper(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        arch: nn.Module,\n",
    "        dataset,                   # EEGDataset 实例\n",
    "        batch_size: int = 64,\n",
    "        lr: float = 1e-3,\n",
    "        max_epoch: int = 100,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=[\"arch\", \"dataset\"])\n",
    "\n",
    "        self.arch        = arch\n",
    "        self.dataset_obj = dataset        # 原始数据集对象\n",
    "        self.batch_size  = batch_size\n",
    "        self.lr          = lr\n",
    "        self.max_epoch   = max_epoch\n",
    "        self.num_classes = 5              # ←← 改为 5\n",
    "\n",
    "        # --- metrics ---\n",
    "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.val_acc   = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.test_acc  = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "\n",
    "        self.confmat   = ConfusionMatrix(\n",
    "            task=\"multiclass\", num_classes=self.num_classes\n",
    "        )\n",
    "        self.f1score   = MulticlassF1Score(num_classes=self.num_classes)\n",
    "\n",
    "        # --- recorders ---\n",
    "        self.tr_loss_meter, self.val_loss_meter = AvgMeter(), AvgMeter()\n",
    "        self.tr_acc_meter , self.val_acc_meter  = AvgMeter(), AvgMeter()\n",
    "\n",
    "        # 关闭手动优化，Lightning 自动反向传播/step\n",
    "        self.automatic_optimization = True\n",
    "\n",
    "    # ---------------- core ----------------\n",
    "    def forward(self, x):\n",
    "        return self.arch(x)\n",
    "\n",
    "    def _shared_step(self, batch):\n",
    "        x, y = batch\n",
    "        y    = y.long().squeeze()       # shape -> (B,)\n",
    "        logits = self(x)\n",
    "        loss   = F.cross_entropy(logits, y)\n",
    "        preds  = torch.argmax(logits, dim=1)\n",
    "        return loss, preds, y\n",
    "\n",
    "    def training_step(self, batch, _):\n",
    "        loss, preds, y = self._shared_step(batch)\n",
    "        self.tr_loss_meter.update(loss)\n",
    "        self.tr_acc_meter.update(self.train_acc(preds, y))\n",
    "        self.log_dict(\n",
    "            {\"train/loss\": loss, \"train/acc\": self.train_acc(preds, y)},\n",
    "            on_step=False, on_epoch=True, prog_bar=True, sync_dist=True\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        rank_zero_only(\n",
    "            lambda: print(\n",
    "                f\"[Epoch {self.current_epoch}] \"\n",
    "                f\"train_loss={self.tr_loss_meter.show():.4f}, \"\n",
    "                f\"train_acc={self.tr_acc_meter.show():.4f}\"\n",
    "            )\n",
    "        )\n",
    "        self.tr_loss_meter.reset()\n",
    "        self.tr_acc_meter.reset()\n",
    "\n",
    "    def validation_step(self, batch, _):\n",
    "        loss, preds, y = self._shared_step(batch)\n",
    "        self.val_loss_meter.update(loss)\n",
    "        self.val_acc_meter .update(self.val_acc(preds, y))\n",
    "        self.log_dict(\n",
    "            {\"val/loss\": loss, \"val/acc\": self.val_acc(preds, y)},\n",
    "            on_step=False, on_epoch=True, prog_bar=True, sync_dist=True\n",
    "        )\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        rank_zero_only(\n",
    "            lambda: print(\n",
    "                f\"[Epoch {self.current_epoch}] \"\n",
    "                f\"val_loss={self.val_loss_meter.show():.4f}, \"\n",
    "                f\"val_acc={self.val_acc_meter.show():.4f}\"\n",
    "            )\n",
    "        )\n",
    "        self.val_loss_meter.reset()\n",
    "        self.val_acc_meter.reset()\n",
    "\n",
    "    def test_step(self, batch, _):\n",
    "        loss, preds, y = self._shared_step(batch)\n",
    "        self.test_acc.update(preds, y)\n",
    "        self.confmat .update(preds, y)\n",
    "        self.log_dict(\n",
    "            {\"test/loss\": loss},\n",
    "            on_step=False, on_epoch=True, prog_bar=True, sync_dist=True\n",
    "        )\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        cm = self.confmat.compute().cpu().numpy()\n",
    "        acc = self.test_acc.compute().item()\n",
    "        f1  = self.f1score.compute().item()\n",
    "        rank_zero_only(lambda: print(f\"\\nTest ACC={acc:.4f}, F1={f1:.4f}\\nConfusion‑Matrix:\\n{cm}\"))\n",
    "        self.confmat.reset()\n",
    "\n",
    "        # ------ 详细分类报告 ------\n",
    "        if rank_zero_only.rank == 0:\n",
    "            report = classification_report(\n",
    "                y_true = np.concatenate([t.cpu().numpy() for t in self.confmat.target]),\n",
    "                y_pred = np.concatenate([p.cpu().numpy() for p in self.confmat.preds]),\n",
    "                target_names=[\"Left\",\"Right\",\"Up\",\"Down\",\"Rest\"],\n",
    "                digits=4\n",
    "            )\n",
    "            print(report)\n",
    "\n",
    "    # ---------------- data loaders ---------------\n",
    "    def train_dataloader(self):\n",
    "        return self.dataset_obj.get_loaders(\n",
    "            batch_size=self.batch_size, num_workers=os.cpu_count()\n",
    "        )[0]\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.dataset_obj.get_loaders(\n",
    "            batch_size=self.batch_size, num_workers=os.cpu_count()\n",
    "        )[1]\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.dataset_obj.get_loaders(\n",
    "            batch_size=self.batch_size, num_workers=os.cpu_count()\n",
    "        )[2]\n",
    "\n",
    "    # --------------- optim & sched ---------------\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=self.lr,\n",
    "            total_steps=self.trainer.estimated_stepping_batches,\n",
    "            pct_start=0.3,\n",
    "            anneal_strategy=\"cos\",\n",
    "            final_div_factor=1e2,\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\"scheduler\": scheduler, \"interval\": \"step\"},\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2b56a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_all shape: (1644, 8, 250)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory D:\\data\\code\\eeg\\src exists and is not empty.\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    }
   ],
   "source": [
    "# ============= 0. 依赖 =============\n",
    "import os, random, numpy as np, torch, torch.nn as nn, torch.nn.functional as F\n",
    "import pytorch_lightning as L\n",
    "from torchmetrics.classification import Accuracy, ConfusionMatrix, MulticlassF1Score\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "# ============= 1. 随机种子 =============\n",
    "SEED = 42\n",
    "L.seed_everything(SEED, workers=True)\n",
    "\n",
    "# =========================================================\n",
    "# ----------------- 模型组件定义 ---------------------------\n",
    "# =========================================================\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Transformer 常用位置编码 (batch, seq_len, embed_dim)\"\"\"\n",
    "    def __init__(self, embed_dim: int, dropout: float, max_len: int = 1000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, embed_dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, embed_dim, 2).float() * (-np.log(10000.0) / embed_dim)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)   # (1, max_len, embed_dim)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, : x.size(1)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\"简化版 Encoder Block\"\"\"\n",
    "    def __init__(self, embed_dim: int, num_heads: int,\n",
    "                 dim_feedforward: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads,\n",
    "                                          dropout=dropout, batch_first=True)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, dim_feedforward),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim_feedforward, embed_dim),\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Self‑Attention\n",
    "        attn_out, _ = self.attn(x, x, x)\n",
    "        x = self.norm1(x + self.drop(attn_out))\n",
    "        # Feed‑Forward\n",
    "        ffn_out = self.ffn(x)\n",
    "        x = self.norm2(x + self.drop(ffn_out))\n",
    "        return x\n",
    "\n",
    "\n",
    "class EEGClassificationModel(nn.Module):\n",
    "    \"\"\"\n",
    "    整体架构：\n",
    "    Conv1d → BatchNorm → Conv1d → BatchNorm →\n",
    "    2×TransformerBlock → MLP → 5‑way logits\n",
    "    \"\"\"\n",
    "    def __init__(self, eeg_channel: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(eeg_channel, eeg_channel, kernel_size=11,\n",
    "                      stride=1, padding=5, bias=False),\n",
    "            nn.BatchNorm1d(eeg_channel),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv1d(eeg_channel, eeg_channel * 2, kernel_size=11,\n",
    "                      stride=1, padding=5, bias=False),\n",
    "            nn.BatchNorm1d(eeg_channel * 2),\n",
    "        )\n",
    "\n",
    "        self.transformer = nn.Sequential(\n",
    "            PositionalEncoding(eeg_channel * 2, dropout),\n",
    "            TransformerBlock(eeg_channel * 2, num_heads=4,\n",
    "                             dim_feedforward=eeg_channel // 4, dropout=dropout),\n",
    "            TransformerBlock(eeg_channel * 2, num_heads=4,\n",
    "                             dim_feedforward=eeg_channel // 4, dropout=dropout),\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(eeg_channel * 2, eeg_channel // 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(eeg_channel // 2, 5),   # ← 5 类\n",
    "        )\n",
    "\n",
    "    def forward(self, x):          # x: (B, C, T)\n",
    "        x = self.conv(x)           # (B, 2C, T)\n",
    "        x = x.permute(0, 2, 1)     # (B, T, 2C)\n",
    "        x = self.transformer(x)    # (B, T, 2C)\n",
    "        x = x.permute(0, 2, 1)     # (B, 2C, T)\n",
    "        x = x.mean(dim=-1)         # (B, 2C)\n",
    "        return self.mlp(x)         # (B, 5)\n",
    "\n",
    "# =========================================================\n",
    "# ---------------- Lightning 包装器 ------------------------\n",
    "# =========================================================\n",
    "class ModelWrapper(L.LightningModule):\n",
    "    def __init__(self, arch: nn.Module, dataset,\n",
    "                 batch_size: int = 64, lr: float = 2e-3, max_epoch: int = 100):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=[\"arch\", \"dataset\"])\n",
    "        self.arch        = arch\n",
    "        self.dataset_obj = dataset\n",
    "        self.num_classes = 5\n",
    "\n",
    "        # metrics\n",
    "        self.tr_acc = Accuracy(task=\"multiclass\", num_classes=5)\n",
    "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=5)\n",
    "        self.test_acc = Accuracy(task=\"multiclass\", num_classes=5)\n",
    "        self.confmat = ConfusionMatrix(task=\"multiclass\", num_classes=5)\n",
    "        self.f1 = MulticlassF1Score(num_classes=5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.arch(x)\n",
    "\n",
    "    # ------ shared step ------\n",
    "    def _common_step(self, batch):\n",
    "        x, y = batch\n",
    "        y = y.long().squeeze()\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        return loss, preds, y\n",
    "\n",
    "    # ------ train / val / test ------\n",
    "    def training_step(self, batch, _):\n",
    "        loss, preds, y = self._common_step(batch)\n",
    "        self.log_dict({\"train/loss\": loss,\n",
    "                       \"train/acc\": self.tr_acc(preds, y)},\n",
    "                      prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, _):\n",
    "        loss, preds, y = self._common_step(batch)\n",
    "        self.log_dict({\"val/loss\": loss,\n",
    "                       \"val/acc\": self.val_acc(preds, y)},\n",
    "                      prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "    def test_step(self, batch, _):\n",
    "        loss, preds, y = self._common_step(batch)\n",
    "        self.confmat.update(preds, y)\n",
    "        self.log(\"test/loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log(\"test/acc\", self.test_acc(preds, y), prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        cm = self.confmat.compute().cpu().numpy()\n",
    "        acc = self.test_acc.compute().item()\n",
    "        f1  = self.f1.compute().item()\n",
    "        print(f\"\\nTest ACC={acc:.4f}  F1={f1:.4f}\\nConfusion‑Matrix:\\n{cm}\")\n",
    "\n",
    "    # ------ loaders ------\n",
    "    def train_dataloader(self):\n",
    "        return self.dataset_obj.get_loaders(batch_size=self.hparams.batch_size)[0]\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.dataset_obj.get_loaders(batch_size=self.hparams.batch_size)[1]\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.dataset_obj.get_loaders(batch_size=self.hparams.batch_size)[2]\n",
    "\n",
    "    # ------ optim ------\n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.AdamW(self.parameters(), lr=self.hparams.lr, weight_decay=1e-4)\n",
    "        sched = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            opt, max_lr=self.hparams.lr,\n",
    "            total_steps=self.trainer.estimated_stepping_batches,\n",
    "            pct_start=0.3, div_factor=25.0, final_div_factor=1e2\n",
    "        )\n",
    "        return {\"optimizer\": opt, \"lr_scheduler\": {\"scheduler\": sched, \"interval\": \"step\"}}\n",
    "\n",
    "# =========================================================\n",
    "# -------------------- 一键训练脚本 ------------------------\n",
    "# =========================================================\n",
    "# ==== 假设你已经执行过预处理，得到了 X_all, y_all, eeg_dataset ====\n",
    "print(\"X_all shape:\", X_all.shape)      # (n_segments, 8, 250)\n",
    "\n",
    "EEG_CHANNEL   = X_all.shape[1]          # 通道数 8\n",
    "MAX_EPOCH     = 80\n",
    "BATCH_SIZE    = 64\n",
    "LR            = 2e-3\n",
    "CHECKPOINT_DIR = os.getcwd()\n",
    "\n",
    "# -- 构建基础模型 --\n",
    "base_model = EEGClassificationModel(eeg_channel=EEG_CHANNEL, dropout=0.20)\n",
    "\n",
    "if torch.cuda.is_available() and int(torch.__version__.split('.')[0]) >= 2:\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "    base_model = torch.compile(base_model)\n",
    "\n",
    "# -- LightningModule --\n",
    "wrapper = ModelWrapper(\n",
    "    arch       = base_model,\n",
    "    dataset    = eeg_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    lr         = LR,\n",
    "    max_epoch  = MAX_EPOCH,\n",
    ")\n",
    "\n",
    "# ---- 回调 ----\n",
    "ckpt_cb = ModelCheckpoint(\n",
    "    dirpath   = CHECKPOINT_DIR,\n",
    "    filename  = \"best-{epoch:02d}-{val_acc:.4f}\",\n",
    "    monitor   = \"val/acc\",\n",
    "    mode      = \"max\",\n",
    "    save_top_k= 1,\n",
    ")\n",
    "early_cb = EarlyStopping(monitor=\"val/acc\", mode=\"max\", patience=12, verbose=True)\n",
    "lr_cb    = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "logger   = CSVLogger(save_dir=CHECKPOINT_DIR, name=\"eeg_log\")\n",
    "\n",
    "# ---- Trainer ----\n",
    "trainer = L.Trainer(\n",
    "    max_epochs        = MAX_EPOCH,\n",
    "    accelerator       = \"auto\",\n",
    "    precision         = \"bf16-mixed\" if torch.cuda.is_available() else 32,\n",
    "    gradient_clip_val = 1.0,\n",
    "    callbacks         = [ckpt_cb, early_cb, lr_cb],\n",
    "    logger            = logger,\n",
    "    log_every_n_steps = 10,\n",
    "    deterministic     = True,\n",
    ")\n",
    "\n",
    "# ---- 训练 & 测试 ----\n",
    "trainer.fit(wrapper)\n",
    "trainer.test(wrapper, ckpt_path=ckpt_cb.best_model_path)\n",
    "print(\"Best checkpoint:\", ckpt_cb.best_model_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
